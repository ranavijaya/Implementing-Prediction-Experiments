{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rapid-prague"
      },
      "source": [
        "# Programming Assignment 2\n",
        "\n",
        "In this assignment, you will:\n",
        "\n",
        "1. Practice writing code to train and evaluate models using both the two-way holdout method, and an evaluation approach appropriate for models with hyperparameters that uses k-fold cross validation plus a test set.\n",
        "\n",
        "2. Practice writing code to optimize a machine learning model. In particular, we will use gradient descent to optimize a logistic regression model.\n",
        "\n",
        "3. **574 Only**: Perform optimization with a different algorithm (Newton-Raphson)\n",
        "\n",
        "# Resources you can use to complete this assignment (a COMPLETE list)\n",
        "\n",
        "**NOTE: You ARE allowed to use Google to find things that fit this list (i.e. it is often easy to google something like \"plotly draw line graph\" to find the right part of the plotly documentation).**\n",
        "\n",
        "- Anything linked to in this article\n",
        "- Anything linked to from the course web page\n",
        "- Any materials from another online course taught at a university (**if you use this, you MUST provide a link to the exact document used**)\n",
        "- Anything posted by Kenny, Navid, or Yincheng on Piazza\n"
      ],
      "id": "rapid-prague"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "everyday-packing"
      },
      "source": [
        "\n",
        "# Grading\n",
        "\n",
        "For grading of code in Part 2, we will execute the submitted notebook as follows:\n",
        "\n",
        "```shell\n",
        "jupyter nbconvert --to python Assignment2-Student.ipynb\n",
        "python Assignment2-Student.py\n",
        "```\n",
        "\n",
        "The PDF that comes along with this document has other details on the points awarded for each part.\n",
        "\n",
        "As such, you will submit, one member of your group will subit as a zip file on UBLearns, a ```.zip``` file that contains 4 things:\n",
        "- Your completed jupyter notebook.\n",
        "- Your written report, answering all questions asked here (and copied in the assignment PDF)\n",
        "- `part_1.1_results.csv`\n",
        "- `part_1.4_results.csv`\n"
      ],
      "id": "everyday-packing"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adjustable-double"
      },
      "source": [
        "# Part 1 - Predicting Review Scores on Pitchfork\n",
        "\n",
        "For Part 1, we will be using data from [this paper](https://ojs.aaai.org/index.php/ICWSM/article/view/7355). The data is a collection of reviews from [Pitchfork](https://pitchfork.com/), a site that provides expert reviews of music album. The authors of this paper have also combined the data with a set of features from [Spotify’s API](https://developer.spotify.com/documentation/web-api/) that provide insight into the music itself, e.g. the \"acousticness\" of the song.  We will tackle a regression problem here, trying to predict the score of a review from several of the other columns in the dataset.\n",
        "\n",
        "## Part 1.1 - Feature Engineering with Feature Subsets\n",
        "\n",
        "In the first subsection of Part 1, we’re going to rely on our old friend linear regression. We’re going to look at how running linear regression with various subsets of our features impacts our ability to predict score.\n",
        "\n",
        "In Part 1.1, your task is to write code below that trains a separate linear regression model for a number of different feature subsets.  Specifically:\n",
        "\n",
        "- The list `feature_sets` below is a list of lists; each sublist is a different subset of features to build a model with. \n",
        "- All models should be trained on the dataset `part1_train.csv`. \n",
        "- For each of these trained models, you should evaluate the model’s predictions on the training dataset, as well as the provided test set, called `part1_test.csv`. The evaluation metric we will use is **root mean squared error**.  \n",
        "\n",
        "Write out the result to a file called `part_1.1_results.csv` and submit this along with your assignment. The file should have the following columns:\n",
        "- `feature_set` - a column describing the features of the model used. For feature sets with multiple features, combine them using an underscore (you can do this with the code `\"_\".join(feature_set)`)\n",
        "- `training_rmse` - a column that gives the RMSE of a linear regression model trained on this feature set on the training data\n",
        "- `test_rmse` - a column that gives the RMSE of a linear regression model trained on this feature set on the test data\n",
        "\n",
        "In addition, please answer the following questions:\n",
        "- **1.1.1** Which model had the best RMSE on the *training data*? \n",
        "- **1.1.2** Which model had the best RMSE on the *test data*? \n",
        "- **1.1.3** Which feature do you believe was the most important one? Why? *(Note: There is more than one perfectly acceptable way to answer this question)*\n",
        "- **1.1.4** What can we say about the utility of the Spotify features based on these results?"
      ],
      "id": "adjustable-double"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waiting-bunch"
      },
      "outputs": [],
      "source": [
        "feature_sets = [['artist'],\n",
        " ['reviewauthor'],\n",
        " ['releaseyear'],\n",
        " ['recordlabel'],\n",
        " ['genre'],\n",
        " ['danceability'],\n",
        " ['energy'],\n",
        " ['key'],\n",
        " ['loudness'],\n",
        " ['speechiness'],\n",
        " ['acousticness'],\n",
        " ['instrumentalness'],\n",
        " ['liveness'],\n",
        " ['valence'],\n",
        " ['tempo'],\n",
        " ['danceability','energy','key','loudness','speechiness','acousticness',\n",
        "  'instrumentalness','liveness','valence','tempo'],\n",
        " ['artist', 'reviewauthor', 'releaseyear', 'recordlabel', 'genre'],\n",
        " ['artist', 'reviewauthor', 'releaseyear', 'recordlabel', 'genre', 'danceability', \n",
        "  'energy', 'key', 'loudness', 'speechiness', 'acousticness', 'instrumentalness',\n",
        "  'liveness', 'valence', 'tempo']]\n"
      ],
      "id": "waiting-bunch"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk_FuBjnEd_u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Convenience things for you, note that releaseyear is continuous but is not a Spotify API variable\n",
        "CONTINUOUS_FEATURES = ['releaseyear', 'danceability', 'energy', 'key', 'loudness',\n",
        "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
        "       'valence', 'tempo']\n",
        "CATEGORICAL_FEATURES = ['artist', 'reviewauthor', 'recordlabel', 'genre']\n",
        "\n",
        "# Read in the data\n",
        "training_data = pd.read_csv(\"part1_train.csv\")\n",
        "test_data = pd.read_csv(\"part1_test.csv\")\n",
        "\n",
        "result_data = []\n",
        "target_var = training_data.score\n",
        "target_var_test = test_data.score\n"
      ],
      "id": "sk_FuBjnEd_u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caring-aluminum"
      },
      "outputs": [],
      "source": [
        "\n",
        "#continuous_rescaled_X = StandardScaler().fit_transform(training_data[CONTINUOUS_FEATURES].values)\n",
        "#categorical_X, feature_labels =  onehot_encode_var(training_data, CATEGORICAL_FEATURES)\n",
        "#X = np.concatenate((continuous_rescaled_X,categorical_X), axis=1)\n",
        "#print(X)\n",
        "\n",
        "y_train = target_var\n",
        "y_test = target_var_test\n",
        "\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "results_11 = []\n",
        "for feature_set in feature_sets:\n",
        "    # Write your code for Part 1.1 here!\n",
        "    to_transform = []\n",
        "    # imputed_X_train = pd.DataFrame(imputer.fit_transform(training_data))\n",
        "    # imputed_X_train.columns = training_data.columns\n",
        "\n",
        "    # imputed_X_test = pd.DataFrame(imputer.transform(test_data))\n",
        "    # imputed_X_test.columns = test_data.columns\n",
        "\n",
        "    imputed_X_train = training_data[feature_set]\n",
        "    imputed_X_test = test_data[feature_set]\n",
        "\n",
        "\n",
        "    for ele in feature_set:\n",
        "        if ele in CATEGORICAL_FEATURES:\n",
        "            to_transform.append(ele)\n",
        "    if len(to_transform) != 0:\n",
        "        encoder = OneHotEncoder(categories='auto',handle_unknown = 'ignore')\n",
        "        X_train_cat = encoder.fit_transform(imputed_X_train[to_transform]).toarray()\n",
        "        X_test_cat = encoder.transform(imputed_X_test[to_transform]).toarray()\n",
        "\n",
        "        X_train = np.hstack((imputed_X_train[[i for i in feature_set if i not in to_transform ]].values, X_train_cat))\n",
        "        X_test = np.hstack((imputed_X_test[[i for i in feature_set if i not in to_transform ]].values, X_test_cat))\n",
        "\n",
        "\n",
        "    else:\n",
        "        X_train = imputed_X_train[feature_set]\n",
        "        X_test = imputed_X_test[feature_set]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    lnr_mdl = LinearRegression()\n",
        "    lnr_mdl.fit(X_train, y_train)\n",
        "    preds = lnr_mdl.predict(X_test)\n",
        "    preds_train = lnr_mdl.predict(X_train)\n",
        "\n",
        "    abs_diff = abs(preds-y_test)\n",
        "    abs_diff_train = abs(preds_train-y_train)\n",
        "\n",
        "    rmse_calc = np.sqrt(np.mean(np.square(preds - y_test)))\n",
        "    rmse_train = np.sqrt(np.mean(np.square(preds_train - y_train)))\n",
        "#result_data.append(rmse_calc)\n",
        "    # print(rmse_calc)\n",
        "    # results_11.append({'feature_set':feature_set,'#features': len(feature_set),'train_rmse':rmse_train,'test_rmse':rmse_calc})\n",
        "    results_11.append([i in feature_set for i in feature_sets[-1]] + [rmse_train, rmse_calc])\n"
      ],
      "id": "caring-aluminum"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "r3G2ludxiN4p",
        "outputId": "d77ff846-80b1-4066-ac27-3ab5a576dff8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa61ba97650>"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAFFCAYAAADfHkeOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd7xkVZW2n7ebJuesklVABknTgigKiEgUlMGAYEAUI4IJ4wfmGVDHOAYERJQgII6KIDBI0CGHhiYqAyiNQKNEUaC77/v9sU/R1Zd7q/YJ91bVrfX07/xu1zlnnb3vrTqr9ll7rXfLNkEQBEH/MK3XHQiCIAgWJRxzEARBnxGOOQiCoM8IxxwEQdBnhGMOgiDoMxabzMY2XG1m5RSQm245rcmuBEHQhfkX/LiW/bQtd6plv8SG26nWBYB5f70jy+fMWHWD2m01SYyYgyAI+oxajlnSrpJuk3S7pI831akgCIJGGFmQt/UZlR2zpOnAfwG7AZsA+0napKmOBUEQ1MYjeVufUSfGvDVwu+07ACSdCuwN3NxEx4IgCOriBfN73YVK1HHMzwHubns9B9imXneCIAgaZKT/RsM5TGpWRhAEwaTSh2GKHOpM/t0DrN32eq1i3yJIOljS1ZKufuSJB2o0FwRBUJJhm/wDrgKeL2l9SYsDbwR+Ofok28fYnml75gpLrlajuSAIgpIM2+Sf7fmS3g+cC0wHjrd9U2M9C4IgqMkwTv5h+2zg7Ib6EgRB0Cwx+RcEQdBn9GGYIodJdcx19C7+5QWv71nbQTCMXHvo7Fr2629wUS37Z196YS17oC8n9nKIEXMQBFOXAR0x19XKOF7SXEk3NtWhIAiCxhgZydsy6ObvJO0v6QZJsyVdKmnzUcenS7pO0lnd2qqrLncCsGvNawRBEEwMC+bnbXmcQGd/dyewve0XAp8Hjhl1/FDglpyGajlm25cAD9a5RhAEwURhL8ja8q7V2d/ZvtT2Q8XLy0lFdwBIWgvYAzg2p63QYw6CYOqSWWDSXqFcbAfXbPkg4Jy2118HDgey4iYx+RcEwdQlM35s+xieGXqohKQdSY55u+L1nsBc29dI2iHnGhM+Ym7/Jjr2xFMmurkgCIKFTHJJtqTNSOGKvW3/rdj9UmAvSXcBpwKvkPSTTteZ8BFz+zdR7vpbQRAEjTCJecyS1gHOBN5s+w+t/bY/AXyiOGcH4CO2D+h0rVqOWdIpwA7AqpLmAEfaPq7ONYMgCBqjQa2MsfwdMAPA9veAI4BVgO9IAphve2aVtupqZexXxz4IgmBCaTBM0c3f2X4H8I4u51wEXNStrZj8C4Jg6hIiRhNLXa2L0NoIgnL8689eW8ve/3ysoZ7UIBxzEARBf5FbPNJvVHbMktYGTgTWAAwcY/sbTXUsCIKgNkMolD8f+LDtayUtB1wj6XzbNzfUtyAIgnoMWyjD9r3AvcX/H5N0C/AcIBxzEAT9wYDKfjYSY5a0HrAlcEUT1wuCIGiEYRsxt5C0LPAz4DDbj9bvUhAEQUMM6Ii5rlD+DJJTPsn2meOcE1oZQRD0hgaF8ieTOlkZAo4DbrH9n+OdF1oZQRD0jAHNyqgzYn4p8GaSUtKsYtu9oX4FQRDUZ9hGzLZ/D6jBvgRBEDTLgMaYo/IvCIKpSx+OhnMYGsfcS62N0NkIBpEnv3d8LfvFD9q/oZ7UIEbMQRAEfcawjZglLQlcAixRXOcM20c21bEgCILaLBgyESPgSeAVtv9e5DP/XtI5ti9vqG9BEAT1GLYRs20Dfy9ezii2yFMOgqB/GFDHXLfyb7qkWcBc4HzboZURBEH/MMmrZDdFLcdse4HtLYC1gK0lbdpMt4IgCBpgQAtMajnmFrYfBi4Edh19LLQygiDoGQsW5G19Rp2sjNWAebYflrQUsDNw1OjzQisjCIKe0Yej4RzqZGU8C/iRpOmkkfdpts9qpltBEAQN0Ifx4xzqZGXcQBLHD4Ig6Es80txDuqTjgT2BubafMZ8maX/gYyQNoceA99i+vsr6qI3EmIMgCPqSZif/TmCMebQ27gS2t/1C4PMUIVwWro+6CfBi4H2SNunUUJRkZ1JH76KOzkbdtoOgKou/fb9ed6E+DYYybF9SLKM33vFL215eTspWq7Q+ajjmIAimLvN7lnFxEHDO6J2566OGYw6CYOqSGaaQdDBwcNuuY4qMstJI2pHkmLcbtT97fdQmFmOdDlwN3GN7z7rXC4IgaAznTf61p/XWQdJmwLHAbrb/1ra/6/qo7TQxYj4UuAVYvoFrBUEQNMck5jFLWgc4E3iz7T+07c9aH7WduloZawF7kL4hgiAI+osR520ZSDoFuAzYSNIcSQdJerekdxenHAGsAnynWAP16mJ/6fVR646Yvw4cDixX8zpBEATN02C5te2OaSq23wG8Y4z9pddHrTxiltRKtL6my3mhlREEQU/wyEjW1m/UGTG/FNirGJIvCSwv6Se2D2g/KbQygiDoGQ1W/k0mlUfMtj9hey3b6wFvBH472ikHQRD0lAHVY4485iAIpi4DOmJuxDHbvgi4qIlrBUEQNEYfxo9ziBHzJFBX6yK0NoJeoJWfXc9e0xvqSQ36UAQ/h3DMQRBMXYY5lBEEQdCP9GMqXA61HLOku0iC0AuA+bZnNtGpIAiCRhjiEfOOtv/awHWCIAiaZYgdcxAEQX/ShznKOdR1zAbOk2Tg+1X1S4MgCCYCzx9Mx1x3zb/tbG8F7EZax+rlo08IrYwgCHpGg+pyk0mtEbPte4qfcyX9HNgauGTUOaGVEQRBbxjQrIw66nLLSFqu9X/gVcCNTXUsCIKgNkM4Yl4D+HkS52cx4GTbv2mkV0EQBE3Qh043h8qO2fYdwOYN9iUIgqBRvGAwQxmRLjcAhNZG0Avqal14ZF5DPanBsI2YgyAI+h2HYw6CIOgzBtQx110le0VJZ0i6VdItkrZtqmNBEAS1Gcnc+oy6I+ZvAL+xva+kxYGlG+hTEARBIwxdKEPSCsDLgbcB2H4KeKqZbgVBEDTA/MF0zHVCGesDDwA/lHSdpGOLQpMgCIK+wCPO2vqNOo55MWAr4Lu2twQeBz4++qTQygiCoGc0GGOWdLykuZLGrHCWtL+kGyTNlnSppM3bju0q6TZJt0t6hp8cTZ0Y8xxgju0ritdnMIZjDq2MIAh6RcOj4ROAbwMnjnP8TmB72w9J2o3k97ZRSgj/L2Bnkt+8StIvbd88XkOVR8y27wPulrRRsWsnYNyGgiAIJp0GR8y2LwEe7HD8UtsPFS8vB9Yq/r81cLvtO4q5uFOBvTu1VTcr4xDgpCIj4w7gwJrXC4IgaIxcnXxJBwMHt+06pqa+/EHAOcX/nwPc3XZsDrBNJ+O6sp+zgFjnLwiCvsTzM89rC7nWRdKOJMe8XdVrROVfEARTl0kuHpG0GXAssJvtvxW77wHWbjttrWLfuIRjHgJ6KYIUAkgDzJL1sl+lugsk1Wcyl/yTtA5wJvBm239oO3QV8HxJ65Mc8huBN3W6VjjmIAimLE06ZkmnADsAq0qaAxwJzACw/T3gCGAV4DuFTv182zNtz5f0fuBcYDpwvO2bOrVVp/JvI+Cnbbs2AI6w/fWq1wyCIGiSJh2z7f26HH8H8I5xjp0NnJ3bVh2h/NuALQCKPL17gJ9XvV4QBEHTeIF63YVKNBXK2An4P9t/auh6QRAEtfHIcDvmNwJRbx0EQV8xmZN/TVJ72rQoLtkLOH2c46GVEQRBT7CVtfUbTYyYdwOutX3/WAdDKyMIgl4xqCPmJhzzfkQYIwiCPmQoY8yF/vLOwLua6U4QBEFzjAxjVobtx0kJ1UEQBH3HUI6YgyAI+hkP6KxWOOagK3X0LurobNRtO6iH/3Z395M6Mb337iVGzEEQBH1GP6bC5VArj1nSByXdJOlGSadIWrKpjgVBENTFI3lbv1HZMUt6DvABYKbtTUmqSW9sqmNBEAR1WTAyLWvrN+qGMhYDlpI0D1ga+Ev9LgVBEDTDoMaY6yzGeg/wFeDPwL3AI7bPa6pjQRAEdbHztn6jTihjJdJKr+sDzwaWkXTAGOeFVkYQBD3BI8ra+o06oYxXAnfafgBA0pnAS4CftJ8UWhlBEPSKkQHNyqjjmP8MvFjS0sA/SZrMVzfSqyAIggYY6cPRcA51VjC5QtIZwLXAfOA6Glr+OwiCoAmGccSM7SNJCxIGQRD0HYNaYBKVf0EQTFn6MeMih3DMwYRSV+sitDZ6h1ZZu9ddqM1QhjKCIAj6mUENZdTVyji00Mm4SdJhTXUqCIKgCRZYWVu/UafAZFPgncDWwObAnpKe11THgiAI6jJiZW05SDpe0lxJN45zfGNJl0l6UtJHRh0rJfhWZ8T8AuAK2/+wPR+4GNinxvWCIAgapeFVsk8Adu1w/EGSsNtX2ndWEXyr45hvBF4maZWiyGR3YPBnC4IgmDKMZG452L6E5HzHOz7X9lXAvDEOtwTfFiND8K2OiNEtwFHAecBvgFnAgtHnhVZGEAS9wihra/dTxXZwY32oIPhWt8DkOOA4AElfAuaMcU5oZQRB0BPmZ4Yp2v1U04wSfHsYOF3SAbZ/Mp5N3ayM1Yuf65DiyyfXuV4QBEGT5I6YJ5inBd9szwNagm/jUjeP+WeSViHFVN5n++Ga1wuCIGiMPlk1qrTgW91Qxsvq2AdBEEwkTY6GJZ0C7ACsKmkOSSdoBoDt70lak+RwlwdGitqOTaoIvkXlXxAEU5YmR8y29+ty/D5grXGOlRJ8C8cc9DWhtdE7/M9He92F2vRJKKM04ZiDIJiyLFD/lVvn0DUrY6wyREkrSzpf0h+LnytNbDeDIAjKM4Kytn4jJ13uBJ5Zhvhx4ALbzwcuKF4HQRD0Fc7c+o2ujnmcMsS9gR8V//8R8JqG+xUEQVCbJkuyJ5OqMeY1bN9b/P8+YI2G+hMEQdAYI1M1xtwN2x2fBkIrIwiCXjGooYyqI+b7JT3L9r2SngXMHe/E0MoIgqBXzB/MAXPlEfMvgbcW/38r8ItmuhMEQdAcUzYroyhDvAzYSNIcSQcB/wHsLOmPJIGO/5jYbgZBEJRnyoYyOpQh7tRwX4IgCBplpP8Gw1lE5V8QBFOWfkyFyyEcczClCa2NGsx/qtc9qM2CGDEHQRD0F4M6Yq6qlfG6YinuEUkzJ7aLQRAE1RjUyr+qWhk3kpaSuqTpDgVBEDSFlbf1GzlZGZdIWm/UvlsANKDljkEQDAf9OBrOIWLMQRBMWQbVMdfWyuhGaGUEQdArFihv6zcmfMQcWhlBEPSKQR0xRygjCIIpy6A65kpaGZJeWyzfvS3wa0nnTnRHgyAIyjKMWhk/b7gvQRAEjTKoWhkTPvkXBEHQK5osMBmr2G7U8Y0lXSbpSUkfGXVsRUlnSLpV0i2Stu3UVsSYg6ADvdTa6LXOhpZbtaftN8GCZgMVJwDfBk4c5/iDwAcYew3UbwC/sb2vpMWBpTs1FCPmIAimLE2OmMdZmLr9+FzbVwHz2vdLWgF4OXBccd5Tth/u1FZVrYwvF0PyGyT9XNKK3a4TBEEw2fTJ5N/6wAPADyVdJ+lYSct0MqiqlXE+sKntzYA/AJ+o0NkgCIIJJXfE3F4IV2wHN9iNxYCtgO/a3hJ4HPh4N4OOjKOVcV7by8uBfcv2NAiCYKLJzcpoL4SbAOYAc2xfUbw+gy6OuYkY89uBcxq4ThAEQaMswFnbRGL7PuBuSRsVu3YCbu5kU8sxS/oUMB84qcM5oZURBEFPaDhdbqxiu3dLendxfM2i8O5DwKeLc5YvzA8BTpJ0A7AF8KVObVVOl5P0NmBPYCfb437lhFZGEAS9YqTB0XCHYrvW8fuAtcY5NgvIXlSkkmOWtCtwOLC97X9UuUYQBMFEM6gjwUpaGaQk6+WA8yXNkvS9Ce5nEARBaQZ1aamqWhnHTUBfgiAIGqXJUMZkEiXZQRBMWRb0ugMVCcccBBNIHb2LOjobddsGYMG87ud0Yt5T9ewbwDFiDoIg6C/6MX6cQ1WtjM8XOhmzJJ0n6dkT280gCILyjOCsrd+oqpXxZdub2d4COAs4oumOBUEQ1KVPRIxKU1Ur49G2l8vQn79bEARDTj+OhnOoU/n3ReAtwCPAjo31KAiCoCEmWgdjoqislWH7U7bXJulkvL+5LgVBEDTDoBaYNKEudxLwb+MdDBGjIAh6hTP/9RtVtTKeb/uPxcu9gVvHOzdEjIIg6BX9OBrOoatjLrQydgBWLSTtjgR2L7RFR4A/Ae+eyE4GQRBUYWR84cu+JrQygiCYsgzq5F9U/gVBMGXpx/hxDuGYg6BPqat1UVdrY/bvvlrLnhmL17NvgCkbYw6CIBhUBrXApJJWRtuxD0uypFUnpntBEATVGdR0uapaGUhaG3gV8OeG+xQEQdAIU7bAxPYlwINjHPoaad2//vu6CYIgABZ4JGvrN6oWmOwN3GP7ekkNdykIgqAZ+s/l5lHaMUtaGvgkKYwRBEHQt/Rj/DiHKloZzwXWB66XdBewFnCtpDXHOjm0MoIg6BWDKpRfesRsezaweut14Zxn2v7rOOeHVkYQBD3BDZZkSzoe2BOYa3vTMY5vDPwQ2Ar4lO2vjDo+HbiaFAbes1NbOelypwCXARtJmiPpoOzfJAiCoIc0nJVxAmNkqLXxIPAB4CvjHD8UuCWnoapaGe3H18tpKAiCYLJZ0OD031irOY06PheYK2mP0cckrQXsAXwR+FC3tprQYw6CIOhLbGdt7XNhxXZww135Oim9OOubIkqyB4C6mgdBUIWROVlP3eOiJZZpqCfVyZ3Ya58LaxpJrbj0NZJ2yLEJxxwEwZSlT9LlXgrsJWl3YElgeUk/sX3AeAaVtDIkfUbSPZJmFdvujXQ/CIKgQUbsrG0isf0J22sV83FvBH7bySlD3oj5BODbwImj9n9tdDpIEARBP9GkUP44qznNALD9vaKW42pgeWBE0mHAJrYfLdtWTlZGx5nIIAiCfqXJ4pGMDLX7SAV3nc65CLioW1t1sjLeL+mGItSxUo3rBEEQTAi5WRn9RlXH/F1SafYWwL1AzaUOgiAImmdQS7IrOWbb99teYHsE+AGw9XjnhlZGEAS9YlCF8qvKfj7L9r3Fy9cCz1jdpEVoZQRB0Cv6MUyRQ1fHPM5M5A6StiCJ5N8FvGsC+xgEQVCJfhTBz6GqVsZxE9CXIAiCRunH+HEOUfkXBMGUpR/jxzlMqmMOzYdq3HTLab3uQjCErLjOK2rZ/3y5F9eyf9X9b65lD0x4Vd9EESPmIAimLDFiDoIg6DMGdfKvkohRsf8QSbdKuknS0RPXxSAIgmr0g4hRFSqJGEnaEdgb2Nz2k5JWH8c2CIKgZ0zZUMY4IkbvAf7D9pPFOXOb71oQBEE9+nE0nENVrYwNgZdJukLSxZJe1GSngiAImmCoSrILu5WBFwMvAk6TtIHHqH8s1s46GGD1ZddhhSVXq9rXIAiCUniqTv6NwxzgTCeuJC0wuOpYJ9o+xvZM2zPDKQdBMJks8EjW1m9Udcz/DewIIGlDYHHgr011KgiCoAkGVfazqojR8cDxRQrdU8BbxwpjBEEQ9JJBdUtVRYwAOi4mGARB0GsGNSsjKv8GgNAYCXrBk/Pn1bKfhxrqSXX6MeMih3DMQRBMWaZsKCMIgmBQ6ceMixxyJv+OB/YE5tretNj3U2Cj4pQVgYdtbzFhvQyCIKjAVI4xn8AorQzbb2j9X9JXgUca71kQBEFNBjWU0TWP2fYlwINjHZMk4PVALH8dBEHf0WQe83hKm23HN5Z0maQnJX2kbf/aki6UdHOhxnlot7aqFpi0eBlwv+0/1rxOEARB49jO2jI5Adi1w/EHgQ8AXxm1fz7wYdubkGQs3idpk04N1XXM+9FltCzpYElXS7r6kSceqNlcEARBPk2WZHeKHhTH59q+Cpg3av+9tq8t/v8YcAvwnE5tVXbMkhYD9gF+2um80MoIgqBX5Arltw8gi+3giehPIaG8JXBFp/PqpMu9ErjV9pwa1wiCIJgwcsMUto8BjpnIvkhaFvgZcJjtRzudm7O01CnAZcBGkuZIOqg49EZi0i8Igj6mX/SYJc0gOeWTbJ/Z7fzKWhm231a6d0EQBJNIP6TLFdlrxwG32P7PHJuo/AuCYMrSpGMeR2lzRtHO9yStCVwNLA+MSDoM2ATYDHgzMFvSrOJyn7R9dseO98sGHNwr+1623Wv7Qe57/O7D+7tP5a1uulzT1J0JrWPfy7Z7bT/Ifa9rP8h9r2s/yH2f0vSbYw6CIBh6wjEHQRD0Gf3mmOvmEdax72XbvbYf5L7XtR/kvte1H+S+T2lUBOGDIAiCPqHfRsxBEARDTzjmIAiCPiMccxAEQZ8xtI5Z0nRJJ/W6H4OKpOkNXmuapOWbut4gIWklSZv1uh9Bf9FTxyzpgpx949hOl3Rh1bZtLwDWlbR4WVtJW3XaSlxnXUmvLP6/lKTlStheI+l9klYq2//C/pCqtgV/lPTlboLfHdo/WdLykpYBbgRulvTRTNujC9sZki6Q9ICkA0q0Xdd+GUnTiv9vKGmvQqQm1/6iov2VgWuBH0jK0lAo7LeTdGDx/9UkrZ9rW9isIWnPYlu9pO0Skt4k6ZOSjmhtmbaV7/dhoyeOWdKSxYdy1WLEsHKxrUcXAekWhWMdkbRCja7cAfyvpP8n6UOtLcPuqx220asXjImkdwJnAN8vdq0F/HeJvr8BeDZwlaRTJe1SiKXkskZhe5qkXUvaAmwO/AE4VtLlhZ5tmVHvJk7Sh68BzgHWJ+kJ5PCqwnZP4C7geUCWU2/I/hJgSUnPAc4j9fuEEvYrFO3vA5xoexuSjG5XJB0JfAz4RLFrBvCT3IYlvR64EngdaVm4KyTtW6LvvwD2Jq3K8Xjb1qnN2vf70NGLOnDgUOBO4EmSc7yz2K4H3l/iOr8A/kxSbvpmaythf+RY2yT9DWYBiwPXte2bXeE604C9gHuKv8VngZUzbQXsApwK3A58CXhuhT5sX7T/OPAj4HkZNjeRnMrpwPbFvusz27ux+HkssGsZ24bsry1+HgIc3no/S9jPBp5FcuovKvbdUOJzo1Gfmyzb1u8JrN72erUqf7uSn49G7vdh2nqiLmf7G8A3JB1i+1s1LnVmsVXtx2drtI2kpYEPAevYPljS84GNbJ+VYf6k7adaA9ViRZhSSeVFbPJAYHcKrVdgO+C3wBbd7G1b0n3AfaQR0ErAGZLOt314l7anA3sU7a9Helo4ibQO5NnAhl2a/z5ptHo9cImkdYGO4uFtnCXpVuCfwHskrQY8kWnbhL0kbQvsD7T0ycvE3D8HnAv83vZVkjYActfNfKp431x0ZJkS7QJMsz237fXfKPfkfKmkF9qenWvQ4P0+PPTyW4H0OLVc8f9Pk5zsViWvsTiwabHNKGm7GvBlkiP5bWsrYf9T4HAWjsCWJnPkBBwNfBK4FdgZ+DnwxRJtXwNcALwJWGLUsTMz7A8trnFu8T7MKPZPA/4vw/4O0pPKS8Y4lv3UMspusRLnrgxMb/u7r1myrcr2pCeEXwIfK15vUPV3rvA3+gjpS+0O4J2kRSwOKWH/5eI9f1uxnQMcVcL+ZuAp4DbgBtLoP3e0X/t+H5att40XbyhplHcRaQR2RQn7HYA/AReT4n53Ai8vYX8eacRzS3GzHV/yQ3p18bP9sTL3cVzFjXU6Kdb8TopKzEz7DcbYt34J+88C645z7AUZ9svWfO8PJenWtkTEryXFfnNsa93gTTqI4ots+ZI2Rxe/+wzSl+sDwAEl7HcuHOxXgJ0r9Hkf4D+L7bUlbdcda8u0rXW/D9PW28YLhwb8O/Cm9n2Z9teQQget1xsC15Sxb//AFP+/qoT9pcBSLIw5Phe4MsNuOmm9xDp/u2vH+30y7VceY8t+4ij+1hew8GlhM+DTJeyvL37uUjjGfxnrdxrHtu4Xel37kwvHugxpBDkH+GgJ+1nFz9eSvpRWIP8LfX1gybbXSwHrlfzsrEmawHs1mU8KFF8+43xucuc0at3vw7T1Oo/5HknfJ2UYnC1pCcrFu2bYvq31wvYfKFYUyKS1zPi9kvaQtCXpg5bLkcBvgLWVcqIvIIU2OuKUUXKbpHVKtAWApI0l/RuwgqR92ra3AUuWuNS1pJHaH0jxzQeAuyRdK+lfM+x/QMoMmAdg+wbSOpDZv0rxc3fgx7ZvatvXjQXFzz2AY2z/mhTSyqWufZ2MEli4ctAewOm2Hylhezow0vZ6QbEvC0nvIGVlvBbYF7hc0tszTE8ufl5DWqXjmrbt6szm697vQ0Ovl5Z6PbAr8BXbD0t6FuXSlq6WdCwL04X2J/9DAvCFIt3uw8C3SKOgD+Ya2z5f0rXAi0lO5VDbf800Xwm4SdKVtKUb2d6ri91GpDSvFUkjnhaPkcIhuZwPnGH7XABJrwL+Dfgh8B1gmy72S9u+clSW3fwS7V8j6TySU/uEUg73SBebFq0bfGfgqAo3eF37GUXe8muAb9ue15qMy6TO5ONitp9qvXCaQC7zpfJRYEvbfwOQtArpye/4Tka29yx+lsqZHkXd+3146MUwnQYeiwr7JUhZEa3sjA8yaiJsEn6XVrzuq5SI15Fi2s/YSthvW7Pfz0jNY+EjftcJTNJI8bksDOPsC5xTov1pwFbAisXrVYDNMm2XLv7uzy9eP4vM+HRD9h8gpQeeTfpCXhf4Xcm/f/vk4zLkhxTOB/Zqe703cEGJdi8FFm97vThwacm+rwRsDby8tZWw3Q44sPj/apSYFxmmrSeyn5LOsr2npDtJKWLtwy7b3mCS+rEh8F1gDdubFulne9n+Qqb9d0jFCacUu95Aymh434R0OLV5uO2jJX2LMdLrbH8g8zrnkUIvpxa73kAaQe5KirN3rGCUtDUp7/klwEOkidefOjMdqiho2Z80ifm5Iqyzpu0rM+23IznWHxYjzmVt35lj24T9GNdbzHbWE0OdNEtJzyWlJT6bdN/cDbzF9u2ZbZ8IvJBUA2CSY7+h2HCXVZyLUMihpIKoWaSnxctsvyKj7SOBmaTfdUNJzyaFcl6a0/dhYqD1mCW9FPgMacTydFgm17FLupj0KPV921sW+260vWmm/a2kDAYXr39LwSkAABjFSURBVKcBN9l+QYbtPsBRwOqkG0yp6+5YPSfp1bZ/JemtYx23/aPMvq9KipFvR7pB/5eUX/sIyWF0vNGLEM5bSWlb00jhlcOcqthy2v8uKXTxCtsvUCoPP8/2izJsa93gDdivQfpSerbt3ZTK0re1fVym/U9Jsdm3FAOCpUmj1q65523XWBbA9t9zbQq7Izsdd5fcfkmzgRcBl9veQtLGwJds75PR9ixgS9JTVut+u8F2aIWMppfDdcZ4BBtrXwf7W4HdSM5tldZWwv6q4md7uluZCq6zaEsVIn1B/CrT9nYy0tIm6O8+HTip5jU2oMiKAd5BSldcoYR9KwRSJdWwbvVbXftzSPHSVmbJYpSo2qRemuUSpNz1TwJHtLZJ/Oy07plZFGFD0mAkx/bKUe/9MmX+7sO09WTyT9KSpDjfqsVIqRXKWJ5ytfOP2D6nRlf+Wjwatka8+wL3djOS9KvCZjnglmICz6QJs6xHceB+27eU7XBb22Pi7pOH2F6gJKC0uNsmkspg+w5J+5H0Pf4M7GL7nyUuMa+oHmz97Vcjf/KvbvVbXftVbZ8m6RMAtudLWtDNqL19SUux8Hd/LqlcOYdfkJ5qrilh8zSSZgKf4plPmbmj1jmSViS97+dLeohUS5DDacWk64pKWjFvJ5XFB6PoVVbGu4DDSHGya1jomB8Fvt3NWAsV3C6U9GXSxN/TH1Lb12b2432kdcc2lnQPKU66f4ZdllBRF64uHmn/m0X73q3EvIm2YaGA0y9ZNCukW4xxNot+MaxMGoFfIanMDf5NUrXj6pK+SJo8/HSm7Vg3+A8ybZuwf7zIZmg51heTnGUuo9MsX0qqwsthLdu7lmhrNCeRwnezyf8ifBrbry3++xkldccVSL9Lju1XJO1Mus83Io30zy/bh2GgZzHmYrT0Sdufr2B7YYfDdsZERKsPxehxGZKGwGNl+1IVST8cY7dt5+SUNtH+mLFGd48xrtvpuO3c0RNFfHIn0hfzBWWeIIob/FWF7bllb/A69sXA4FskGYAbSdkF+zrlcudeYxUWplle7sw0S0nHAN9yCa2KUfa/t71dRdvppLDFxhXtj7L9sW77gh5P/km6zsUkQEX7DWzf0W1fB/s7SOI/x1cMK7yYdIO+gJR2NB143F0m8Oog6TTbrx9j5NqaPCw1kSJpadv/aLST+W1PJ8mPtj9S/7kXfSmLkujURqS/+22253UxGW3/HJ4ZTrgkw+5mUibQnaQnrVLvu6SdgP1IGTllntRa9r8gaXOUfp8kXetR2T4x+Tc2vS4wuUCpiu1MV/uGOIOUC9vO6UBO5RokTeE3AscVGRXHA6c6VXXl8O3C/nTSLP9b6K6qBtRK1Tu0+LlnZh/Ha39bUjnwssA6kjYH3mX7vXWuW6L9Q0iP9PeTqtdE+qLpepNWzWhpyr5ga5Kq3mLAVkUY58TM9o8ipSfexMJwgkkTqN3YrUQfx+JAYGNShWx727kqjaULoyS9B3gvsIGk9qeK5UjZQMEoej1ifow0MzufVPmUmzK2MUlb4WgWrRxanqRZ8C8V+rI9qex0RZLD/7y7p4xdbXtm+7d+7lNA3VS94vw1SQ7CpNny+0rYXkGK6/6yavt1kHQ7sI2LCrQKtq+u8pTTkP2PScU1s1hY3m3n55DfRiqmKT15V9hXzsGWdJvtjaq0W9hvP9Z+2xd3sFmB5ND/Hfh426HHbD/Ydt5Kth+q2repRE9HzLaXU1rZ4PmU03lopCxZ9TWF/6FUDjtL0tGkjI7c0t5aJc1Kif5HkKRKBXxL0udsdyytbcf23aPaL5NZUJe7KTdh1k6ljJYG7WeS9DKqjmruII1Yq2RVPJ2DTSqfb61gklukcamkTWzfXLbtgt3HihOTFB7HxEkL5BFSCKUTF/DMJ+ChpKeOWWNXEV1KmhAaF9u/AH4haVvbl9Xowh+BC4Ev2760bf8Zkl6eYf9mUlz5/aRy8LVJehM5VErVa6OS5kEbd0t6CWAl3YdDSfKnk8UdwEWSfs2isc6cte+qZrQ0ZX8jSaGtzPvVzj9IX+aj47w5I+7XUhRpFDZ/UYm1Ikn32CylqtvSMWpSdejoybrdxthXhbLLm01Zeh1jPpSFVUQ7FiGKL5WwP7hId1qEEpkNm3mcyqmcm6QtA+GfJH3jMlRN1WvxN9ITQovHin25vBv4Bilv/B6SNvWElZKPwZ+LbXHKKbtBCln9g5RV0aJMnLSu/aqkxWOvZFHH2jWHvOCXxVaFujnYlVLtJilOPLhlyA3T6xjzVbZfpFSquY3tJyXdlBsjLiYOWyxJGk38pUSsr9IE3BgZEYuQM/rQwkVflyKFPx6nKBywPSvDbgvG0Dyw/bZubQf1qBJnHeMaS5FK32/revKidh8hhf52JsVs3w6c7BJLNlWJUU9GnHisrI1hpdeO+eek+O5hwCtIYjgzbO9e8XrTSOuovSTz/EoTcE3k8ko6mRQr/CXpEW5PkpDMeiTdhqPHsaulddB2ndVI8fj1WDRla0LzqFWjclHNCTj9iCTR+nDxeiXgqxP9u7e1/2pSodDitteXtAXwudwRd80c7AkVEqrjXOumz04lej35V7mKaByeT0qByqXSBFyO481gLdJyRn+Hp2+YX5NkFK8hZZyM1XatBWTb+AXwO+B/mNxJv1bl4j6kOG1LS3s/UupcJ1ox8DKa22OxWcspA9h+SGmRhI4UWURjfamUTbf7DCmb5qKi/VlKC7JmUTjiqhVzdWPU3egYJ+4yWu84tzRM9DrG/DRlHgNbtN0orRzY+yg3CVFVK2O8GxSAzBt0dRadlZ9HCqn8U1LX2friQ304KW3w6YwWZ1Y9kr6UJr3iqvU+S/qq7Zlth34lqaPDtf2r4meWgl4HprU/cheZQV3vBdtNObB5th8ZNSDoWB7d4JdC3Rh1N8a9L7pllLSHRIadvnHMVWjgRhlrAu6A3HYlfZ7kyH9MukH2J4mu53ASSV/iF8XrVwMnFzdKTirTSaRVuvckTeS9lbQ8VC5nSdrd9tklbJpkGbVVaUpan5TT3pVibuAjPDMMk/ul9FXgMkmnk963fYEv5nf96X6szqJfirnVcDdJehMwXUmL+QOkjJpxafBLoa5OSB0merQ+ZRhoPWZ4Oj64SB60M0pbR12jklaGpOttb95tXwf7mSzMP/1f29mP6JKusf2vWrS45Spn6BkX5z5GUvh7ijRar1L9VhlJu5K+FO8o2l6XVHl4bobt9cD3SCGfp8Mwtq8p0f4mpHkNgN+WyeuVtBfJuT8bmFv0/ZYSk9ZLkxTeWlkh5wJfsJ27vFTlL4Ui5/h/aItRA69s6umpU5xY0pW2t27FoYv77rISqXrDg/tAe7TqRtIBnk2aNLyQlLb22xL2h5JSp0SSH7yWcksMXUoaJU8nZVbsT8llemr87pcXP88lFclsSVo9Jdd+GikP+4ji9TqkzJjJfP+WIJXFb06JJcEosRr4KLumljS7nqT93Vr1eUfguBL2W9X4m+1Fyr9/nPSEN0KmHnJhP9bq6qU0kemwPFSnvyPpKef7pC/jdwKXkXQ3Ju0zNyjbQI+YVWM1hcL+etubS9qFFA74NGnF5qxZZUnrkXKBX8rCVUAOs31X2d+lLJL2JE3erc3ChWQ/azsrP1Y1VhBpAklvGWu/O+hNFLFgSI/+c0myoe15xB1jlHrmkmZPH6LEkmZaWIp/PanIZ6Tkk9KFpInPM0jLcd2YY1fYXk8a6f+P7S0l7QgcYPugLnZP5yED/9d2aDnS01rXEF5xnVpZHXUySoaJgY4xA0/YfkISkpawfaukMjoArdmX3YETbd+kUTMy4xqmcu732967bKebwAvXh3uENGIryzZOj5PXFdd7SOVWW65L+xfAkqQZ+WuBTkJA17DoGpHtOikmOZ1xcTMrPQM8rLS00yXASZLm0ibo0w2nYqo1SaugfF/S8iQHnbPW5Dzbf5M0TdI02xdK+nqG3cmklVc65iFnUDlOXIQufuu0uvxGwEaSZrikMt8wMOiOuc5qCgDXKC1Kuj7wieIDliUe7qTjXEnXtglUcyFZ6q0gUhvbh7S/Lt7HU8c5vWVT16G22rrA9k7d9nVgb1LY7IOk8NUKlKz8dBKc+mYxej6cpHuS8961vhR+R4kvBefrVXSjTlbHJcDLiqez35DSHt9AuYrX4aDXsZSmNmB7Uvxt8RI200iiKSsWr1ch5bjm2n+XVCDyZlJe7j7APpP0+15MyoVtXzfuxhL2+xd9n0PKSLgNeF0P378ZJF3jnHPf13rPitcrAe/NsFuSFE++vrBpxZfXA24t0dejcvZ1sH8BKZd5NimX+T3A6pm2nyKV0U8nZeJ8gBLrXDbwPlWOE7Nwrb9DgMOL/2evsTlM20CPmIt0tUtIE26l86CdYoN3AhsqrUNYliVJ+hTtaVplNBfqUEudzvZJkq5h4Qoir3E9xbVSaNEKwOkkZ3Vapvk7bf9X64VTGOadwHe62NVa0qyNukI+x5NSHXex/ZcS7UJ6yj0PeLC4xk9dQTq1Kq63PJSUdMD3B1ox8ekT0M2BZ9An/w4kSXRuSxLx+R1wiZP6XI79WOp2lzk/H7ZnSDqHpGp3ulOseF/gINt1hdQnBS2qNzEf+JPtOZm2s0lPNq3H6emkzILcdLVDXEJbos2ukQm0JihCV28gqRnOsf3KSWp3GdLczoJWnBg4xxlx4uI9/zDpb3WUUrXjYc4spR8mBtoxt2ibSPkIsJIzk/EbyOpYi5QR0ZqR/h1JgyHLwdSh+FAfA7yElC54J2l2/q6JbrspJK3BwknAK23PzbT7Mil3+PvFrncBd9v+cKb964Df2H5M0qdJ4awvuMsivsoU8ulg39iyYMVn/nWkFXSWK2Nbh+Ip62Wkv8PvSXHip2xHnLhBBtoxSzoW2ISksfA70gflWttZj/Sqr253Pmm2+8fFrgOA/W3vXPZ3qUrV4pheI+n1wJdJMVaRbvaP2j4jw3YayRm3JuvOB461naX50SrKKSZvv1D04wjb25Tof+n1CiU9y/a9GkcEy3niV+8lDUJWIy1pdpqri96Xpq045BBgKSdRqVm2t8iwnQl8kmdWbEaBySgGOsZMmqybDjxMirn9NdcpF9TN6ljNdvtq1ydIOqyEfWUkfQk42osqpH3Y9qcno/0G+BTwotYoucgK+R9Sbm9HirmBE0ipV6VkMwtaDnwP4Bjbv5aUm82CpPeTJu/uZ9F18zo6GNv3Fj/riGCtTXr8H1cadoKpEyc+iZTiOJtJzAAaSHo9+9jERpo4OozkVOdUvEaVrI4LSKPk6cV2AHDBJP3O142x7xlVXf26AbNHvZ42el8H271IWSR3Fq+3IK1dmNv2WSzMLFiRVIF4fQn726mQCUGaB3l0jO0x4NFevyeZv8P2pGyejxWvNwC+mWn7+173f1C2QQ9l7El6BH456Qa7HPidS6x7p3oLW65LijFvSxoxXQp8wBWWdi+L0ioSL3KxoKeS8PrVrrAQbS8o4sSbAacUu95AmsDrmtlQxDlfAVzkhTras22/MLPtpUkrecy2/UdJzwJeaPu8TPsLgZ1d7uls6JG0EymPevSSWpORxTRQDHooY1dSbPkbLp921FWGsBtOj6S5ywk1zUnABZJaoZQDgbpymJOG7Y8qrUDT+lsfY/vnmeZjyWaWGWGsSqHpLGmdYt+tJezrrFc40NSMEx8IbEy6z9pDQOGYRzHQjtn2+4tR6ybAX4pR42LOnwirJUOoHq6E4ZRudAMLJ8A+7wxltn7C9s+An1UwLS2bOYpfs7C0e0lS5edtJG3rHOqsVzjo1IkTv8h2GcmEoWWgHXNRVHAwqXrruaR85O+RvxJCXdHwSithNIXtc0j6BwODmhF8P4Q0efgkKSvmXPLKmSE1skjIQ9JWpPzkXPvPFnZL2/5Hrt0U4QFnCmWNwaWSNvEkZpEMKoMeY55FKku+omKssdbClkpKXzt40ZUwLs5tvw6S9gGOIq2EIiZZT7kfaNIxlvzcbAscR5qPWEfS5iQt6WznPqhUjRMrxZ3+jzR4urOwLZ2/PSwM9IgZeNL2U61Yo6TFKBFrdL3yUlh0JQxICf+lV8KoyNHAqz2JZdT9gqSXkPSzlwVKO0YtXGkcFuqllJmj+DqwCyk7AdvXS3p5CftBplKcuHgyXZ00EAq6MOiO+WJJnwSWKhzse4FflbmAayxsaftEpXXqWiXc+0ziY9r9w+iUC75GPcfYPo8wnxRzLhXrtn33qMnHyVzQtpfUiRP/jCTWdFWTHZqKDLpj/jgpyX02qRLsbNJIqiMNxTlbrAw83kq3k7R+brpdTa6W9FNScczQpR7VcYxtMeJli9d/L9n83cWo3ZJmkPRWhuVLsk6ceBtgf0l/IkmVRihjHAY6xtxrVHM1h5pt/3CM3Z6MjJBeI+kM4D9JinDbkBzjTNtvzLTflFRG31oR5a/AW525koikVUkr17yS5FzOI2XnTJrKWy+oGyeuU4o+bAykY+4gBgOUq70fVWCyKkkQJrfAZBZFul3b5OMNMQKYWEY5xmmkrIxsxyjpUuBTti8sXu9AEq96ycT0eOog6e+MkVYYzrVZBjWUcWjxc886FxmjwGRxShSYUD/drjJK+tEHkW6S9tWSp/yI2fZfqbfqxTItp1xc76Iy752k9Ukpe+uxaJFFr4qNJpOIE08CA+mYXYjBkLRoT61S9VdQZ/0yAWdJ+j6wYpFT/XbgBxX7UpYfk6rVdgE+R3JUQxHnVJI8/QZJP9ukVTQ+aPuOzEvcIen/sagqYK4tpLj+caSJ5mET44k48SQwkI65jeVIqnCt1RxOt31/CfvKI97C7nXAh6iebleH59l+naS9bf9I0smk8vRh4GTgv0hfrJA0iU8hOY0c3k5ao+9MkmP/XbEvlydsf7PE+VOJXXrdgWFgIGPMo1GF1RyKEe//I62fVrXA5EfAt3vxWCfpSttbS7qElCZ4H0lsvuNK0VOBseL4kq63vfkktf8mUj7ueSyaEdNRaD8Ichn0EXOLuSTH9DdSJVxXGhrxjn6sa117Mh7rjim0OT5NyuddlvRFMwycI+njpFW1TfpSPruovMRdVhNRWuDgdaM0Tk61nTsafCFpAd5XsGiRRd8vSRYMBgM9YlbN1Rzqjnh7kf4zqmrt6d0Lmx4KhbP2rJnWB7j9b9DxqUHSda0smk77OtjfDmxi+6ncPgdBGQZ9xFx3NYdaI94epQi1Jic3Iq2X1xKUeTVwZQ/60ws+Rlqz79FiEm8rkrpebihhRNI6LnSzJa1HOdnQG0n631lrFAZBWQZ6xAyNCN0/g0HIySxiy3u4kDgtskl+bXvKazZo0TX7Pg98hRJr9knalbSQ7cUsXG/wYGfKpkq6iCTyfxWLxpiHIV0umAQGesQ8Rh5yFaH7QWUNoP1R+qli3zDQvmbfD1xyzT7bv1ESfD8YuI6U/vbPEu0fWeLcICjNQDtmagrdDzgnAldKaq368RrghN51Z1K5p8gf3xk4StISpArALCS9g1SktBYwi5QPfRmZk3e2Ly7d4yAoQfaHuU95yikWM+mVd73G9hdJEowPFduBtv+9t72aNF5PKsPepcisWJm0qkYuh5Li83+yvSPpy/3hziYLkfSYpEeL7QlJCyQ9WqL9IOjIwI6Y+6DyrucUk11DlzvrJI5/Ztvre4F7x7d4Bk/YfkISkpawfaukbClL208/lRWfw71Jo+4gaISBnvwrRIw+BLyKNIlz7iRW3gUDShH+ORA4jBS+eAiYYXv3GtfMTrcLgm4MumPuWeVdMDWQtD2wAin9LisvWWlZrxbTSBPQ29vedgK6GAwhg+6YbwWeB/Si8i4YUkZpYc8H7iJlh0Rec9AIAxtjLghBlWBSkTQduMH213rdl2DqMtAj5iDoBS0BqV73I5i6hGMOgpJI+hqpmOmnLBpCG7oMmWBiCMccBCWRdOEYu2071OWCRgjHHAQlkbTB6NVSxtoXBFUZ9Mq/IOgFZ4yx7/RJ70UwZRn0rIwgmDQkbUxa/HaFUbnMy9O2IG4Q1CUccxDksxFpZfYVSfrXLR4D3tmTHgVTkogxB0FJJG1r+7Je9yOYukSMOQjK81pJy0uaIekCSQ9IOqDXnQqmDuGYg6A8r7L9KCmscRdJFqCM7GgQdCQccxCUZ0bxcw/gdNuP9LIzwdQjJv+CoDy/KgS0/gm8p1hr8oke9ymYQsTkXxBUQNLKwCO2F0haGlje9n297lcwNYgRcxBUY2NgPUnt99CJvepMMLUIxxwEJZH0Y+C5pIVcWyt2m3DMQUNEKCMISiLpFmATx80TTBCRlREE5bkRWLPXnQimLhHKCILyrArcLOlK4MnWTtt79a5LwVQiHHMQlOczve5AMLWJGHMQBEGfESPmIMhE0u9tbyfpMVIWxtOHSCuYLN+jrgVTjBgxB0EQ9BmRlREEQdBnhGMOgiDoM8IxB0EQ9BnhmIMgCPqM/w+ya1yogIa/JgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results_11_matrix = pd.DataFrame(results_11, columns = feature_sets[-1] + ['rmse_train', 'rmse_test'])\n",
        "sns.heatmap(results_11_matrix.replace({False:1.25, True:1.13}))"
      ],
      "id": "r3G2ludxiN4p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5t9-d9MizwFx"
      },
      "outputs": [],
      "source": [
        "results_11_matrix.to_csv('part_1.1_results.csv')"
      ],
      "id": "5t9-d9MizwFx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDQSBAtdtjAP"
      },
      "source": [
        "1.1.3 The heatmap indicates the presence of features (in black for all the columns except last 2), and test and train rmse in the last 2 columns.\n",
        "Based on the above Heatmap we can say that presence of 'reviewauthor' resulted in much lower rmse comparatively. So, 'reviewauthor' seems to be most import feature.\n",
        "\n",
        "1.1.4 As seen in the heatmap that the addition of spotify features does not imporve results significantly, and thus are not useful for the linear regression model.**bold text**"
      ],
      "id": "SDQSBAtdtjAP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eyo5Q1a2wukQ",
        "outputId": "68390752-359a-4ee7-8020-4935cfd2d3f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17    1.116982\n",
              "16    1.120437\n",
              "1     1.181263\n",
              "Name: rmse_train, dtype: float64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_11_matrix.iloc[:,-2].sort_values()[:3]"
      ],
      "id": "Eyo5Q1a2wukQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7CM1-uWuzja",
        "outputId": "45d0a1fe-a8eb-449e-d006-0bb53e0d5b0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17    1.176028\n",
              "16    1.177694\n",
              "1     1.195298\n",
              "Name: rmse_test, dtype: float64"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1.1.1 & 1.1.2 the last model had least rmse for test and train for following features {add features from heatmap}\n",
        "results_11_matrix.iloc[:,-1].sort_values()[:3]\n"
      ],
      "id": "z7CM1-uWuzja"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "addressed-mercy"
      },
      "source": [
        "## Part 1.2 - Feature Engineering with the LASSO\n",
        "\n",
        "In Part 1.2, your task is to write code below that trains an L1-regularized linear regression model, with an expanded feature set.  Specifically:\n",
        "\n",
        "1. Begin with the final feature set listed in `feature_sets` (i.e. your feature set, to begin this section, is `feature_sets[-1]`.\n",
        "2. One-hot encode your categorical variables, setting `drop=if_binary` and `sparse=False` in the function arguments. \n",
        "3. Scale all of your continuous features using the `StandardScaler`.\n",
        "4. Train an L1-regularized linear regression model using these features on the dataset `part1_train.csv`. You should use the [LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) class in `sklearn`, it will do the cross-validation necessary to select the appropriate value for the regularizer for you!  Use 10-fold cross-validation to perform model selection (set the `LassoCV` parmaeter `cv` to 10), and set the `random_state` to 1. Do not change any of the other parameters to `LassoCV` (i.e. leave them at their defaults).\n",
        "5. Identify the best `alpha` value (the regularizer term, according to `sklearn`. In class, we refer to this as $\\lambda$!) in terms of average mean squared error according to the cross-validation.\n",
        "6. Finally, train a [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) model on the entire training dataset (`part1_train.csv`). You will use this to report the root mean squared error on the test set (Question 1.2.4 below), and use it in Part 1.3 below as well.\n",
        "\n",
        "**Hint: The proceedure outlined above is very similar to ones we have discussed in class and shown how to do using `Pipeline`s.** \n"
      ],
      "id": "addressed-mercy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loose-width",
        "outputId": "da203701-756a-4f3d-d274-00a5d7fd89fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1223240168890882\n"
          ]
        }
      ],
      "source": [
        "# Write your code for Part 1.2 here\n",
        "from sklearn.linear_model import LassoCV, Lasso\n",
        "\n",
        "# Do the CV to find alpha\n",
        "features = feature_sets[-1]\n",
        "feature_set=features\n",
        "\n",
        "# Retrain the model\n",
        "\n",
        "to_transform = []\n",
        "# imputed_X_train = pd.DataFrame(imputer.fit_transform(training_data))\n",
        "# imputed_X_train.columns = training_data.columns\n",
        "\n",
        "# imputed_X_test = pd.DataFrame(imputer.transform(test_data))\n",
        "# imputed_X_test.columns = test_data.columns\n",
        "\n",
        "imputed_X_train = training_data[feature_set]\n",
        "imputed_X_test = test_data[feature_set]\n",
        "\n",
        "\n",
        "for ele in feature_set:\n",
        "    if ele in CATEGORICAL_FEATURES:\n",
        "        to_transform.append(ele)\n",
        "encoder = OneHotEncoder(categories='auto', drop='if_binary', sparse=False,handle_unknown = 'ignore')\n",
        "X_train_cat = encoder.fit_transform(imputed_X_train[to_transform])\n",
        "X_test_cat = encoder.transform(imputed_X_test[to_transform])\n",
        "\n",
        "X_train = np.hstack((imputed_X_train[[i for i in feature_set if i not in to_transform ]].values, X_train_cat))\n",
        "X_test = np.hstack((imputed_X_test[[i for i in feature_set if i not in to_transform ]].values, X_test_cat))\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# MODIFY FOR LASSO\n",
        "mdl = LassoCV(cv=10, random_state=1)\n",
        "mdl.fit(X_train, y_train)\n",
        "\n",
        "preds = mdl.predict(X_test)\n",
        "preds_train = mdl.predict(X_train)\n",
        "\n",
        "abs_diff = abs(preds-y_test)\n",
        "abs_diff_train = abs(preds_train-y_train)\n",
        "\n",
        "rmse_calc = np.sqrt(np.mean(np.square(preds - y_test)))\n",
        "rmse_train = np.sqrt(np.mean(np.square(preds_train - y_train)))\n",
        "\n",
        "print(rmse_train)\n"
      ],
      "id": "loose-width"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HonR120DKnbk",
        "outputId": "c3512682-d946-48c5-f052-f7c275c66cd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.004477370509664293"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mdl.alpha_"
      ],
      "id": "HonR120DKnbk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQMU7bVCajaW",
        "outputId": "daa0f5d7-1500-4e57-be8e-8e90ce896d90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.1223240168890882"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1.2.3\n",
        "rmse_train"
      ],
      "id": "TQMU7bVCajaW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwb9ehZKan2r",
        "outputId": "5e36712c-2127-483e-ce9b-078ae38a70d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "676"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1.2.1\n",
        "X_test_cat.shape[1] - len(CATEGORICAL_FEATURES)"
      ],
      "id": "Gwb9ehZKan2r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fqXg4PtKgiY"
      },
      "outputs": [],
      "source": [
        "preds = mdl.predict(X_test)\n",
        "preds_train = mdl.predict(X_train)\n",
        "\n",
        "abs_diff = abs(preds-y_test)\n",
        "abs_diff_train = abs(preds_train-y_train)\n",
        "\n",
        "rmse_calc = np.sqrt(np.mean(np.square(preds - y_test)))\n",
        "rmse_train = np.sqrt(np.mean(np.square(preds_train - y_train)))"
      ],
      "id": "1fqXg4PtKgiY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43HaxrMI5-0Z",
        "outputId": "c76d8b90-6340-4c2b-d5e1-d96d1cbcf7f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.18544407371434013"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mdl.score(X_train,y_train)"
      ],
      "id": "43HaxrMI5-0Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtuzRZMlLs77",
        "outputId": "8f278355-59a4-444c-d814-d597a900853b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1.1223240168890882, 1.1646529057502428)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rmse_train, rmse_calc"
      ],
      "id": "NtuzRZMlLs77"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlRKhmDU58ig"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "AlRKhmDU58ig"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "distinct-functionality"
      },
      "source": [
        "Now, answer the following questions:\n",
        "- **1.2.1** - How many total features are introduced by Step 2 above? Provide both the number and an explanation of how you got to this number.\n",
        "- **1.2.2** - What was the best `alpha` value according to your cross-validation results?\n",
        "- **1.2.3** - What was the **average RMSE** of the model with this `alpha` value on the k-fold cross validation on the *training* data?\n",
        "- **1.2.4** - What was the **RMSE** of the model with this `alpha` value on the k-fold cross validation on the *test* data?\n"
      ],
      "id": "distinct-functionality"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYhNpmWSelHK",
        "outputId": "46ffe041-0a18-493b-91b0-b154bf10d633"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((16270, 680), (16270, 691))"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1.2.1\n",
        "# One-hot encode your categorical variables, setting drop=if_binary and sparse=False in the function arguments. \n",
        "X_train_cat.shape, X_train.shape"
      ],
      "id": "wYhNpmWSelHK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6KOuHkCsUPR"
      },
      "outputs": [],
      "source": [
        "mdl_lasso = Lasso(alpha = mdl.alpha_)\n",
        "mdl_lasso.fit(X_train, y_train)\n",
        "# mdl.get_params()\n",
        "preds = mdl_lasso.predict(X_test)\n",
        "preds_train = mdl_lasso.predict(X_train)\n",
        "\n",
        "abs_diff = abs(preds-y_test)\n",
        "abs_diff_train = abs(preds_train-y_train)\n",
        "\n",
        "rmse_calc = np.sqrt(np.mean(np.square(preds - y_test)))\n",
        "rmse_train = np.sqrt(np.mean(np.square(preds_train - y_train)))"
      ],
      "id": "L6KOuHkCsUPR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_OU1vhzcqb9",
        "outputId": "5f57226f-22ce-45ab-835a-789a4c6166ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.1646529057502428"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rmse_calc"
      ],
      "id": "z_OU1vhzcqb9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "floating-vinyl"
      },
      "source": [
        "# Part 1.3 - Interpreting Model Coefficents\n",
        "\n",
        "In this section we will interpret the coefficients from the final model you trained on all of the training data.\n",
        "\n",
        "- **1.3.1** - How many non-zero coefficients are in this final model?\n",
        "- **1.3.2** - What percentage of the coefficients are non-zero in this final model?\n",
        "- **1.3.3** - Who were the three most critical review authors, as estimated by the model? How do you know?\n",
        "- **1.3.4** - Who were the three artists that reviewers tended to like the most?  How do you know?\n",
        "- **1.3.5** - What genre did Pitchfork reviewers tend to like the most? Which genre did they like the least?\n"
      ],
      "id": "floating-vinyl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdzBV53Xehmf",
        "outputId": "7f620ca4-d2b5-49aa-a124-d8d80379b2f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "514"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1.3.1\n",
        "sum(mdl_lasso.coef_ != 0)"
      ],
      "id": "pdzBV53Xehmf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "formal-stable",
        "outputId": "d43b5356-ed65-4545-a3e0-f6f8c96ae98a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.743849493487699"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1.3.2\n",
        "sum(mdl_lasso.coef_ != 0)/len(mdl_lasso.coef_)"
      ],
      "id": "formal-stable"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXLhQBK5s-2A"
      },
      "outputs": [],
      "source": [
        "all_one_hot_vars = []\n",
        "for i in range(4):\n",
        "    all_one_hot_vars += encoder.categories_[i].tolist()\n",
        "\n",
        "all_column_names = []\n",
        "for n,i in enumerate(CATEGORICAL_FEATURES):\n",
        "    all_column_names+= [i] * len(encoder.categories_[n])\n",
        "all_column_names = CONTINUOUS_FEATURES + all_column_names\n",
        "\n",
        "res_1_3_3 = pd.DataFrame([CONTINUOUS_FEATURES + all_one_hot_vars,all_column_names, mdl_lasso.coef_] , index = ['Col_name','Parent_column','Coeff']).T"
      ],
      "id": "SXLhQBK5s-2A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "I_rZV-QXut2t",
        "outputId": "6e023ad9-b209-4b61-ad9a-8494fa9b2e6e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5cb51730-9a8a-4c8a-8556-49325690fe0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Col_name</th>\n",
              "      <th>Parent_column</th>\n",
              "      <th>Coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>Philip Sherburne</td>\n",
              "      <td>reviewauthor</td>\n",
              "      <td>0.058356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>Jenn Pelly</td>\n",
              "      <td>reviewauthor</td>\n",
              "      <td>0.054472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>Marc Masters</td>\n",
              "      <td>reviewauthor</td>\n",
              "      <td>0.040017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cb51730-9a8a-4c8a-8556-49325690fe0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5cb51730-9a8a-4c8a-8556-49325690fe0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5cb51730-9a8a-4c8a-8556-49325690fe0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             Col_name Parent_column     Coeff\n",
              "298  Philip Sherburne  reviewauthor  0.058356\n",
              "211        Jenn Pelly  reviewauthor  0.054472\n",
              "248      Marc Masters  reviewauthor  0.040017"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1.3.3\n",
        "res_1_3_3[res_1_3_3['Parent_column'] == 'reviewauthor'].sort_values('Coeff', ascending = False)[:3]"
      ],
      "id": "I_rZV-QXut2t"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appropriate-lesbian"
      },
      "source": [
        "# Part 1.4 - \"Manual\" Cross-Validation + Holdout for Model Selection and Evaluation\n",
        "\n",
        "We will finally use cross validation for both algorithm and model selection, with a hold-out test set for a final evaluation. We will use **5-fold cross validation** to identify the best parameters and hyperparameters for a set of models. We will then take our final models and use a final hold-out test set (the same one as above) to estimate the generalization error of the models.\n",
        "\n",
        "Specifically, your task is first to write code that trains and evaluates the following models, one for each of the specified hyper parameters sets:\n",
        "\n",
        "- `Decision Tree regression` - All combinations of a `max_depth` of 5, 10, or 20, and a `criterion` of `\"squared error\"` or `\"absolute error\"`. Use the [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor).\n",
        "- Ridge regression - Use the following choices of L2 penalty: $[10^{-5}, 10^{-4}, ..., 10^4, 10^5]$. In Python, you can create a list of these numbers using `np.logspace(-5, 5, 11)`. Use the [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) class from sklearn to train a Ridge Regression model. The parameters you need to pass when constructing the Ridge model are `alpha`, which lets you specify what you want the L2 penalty to be, and `random_state=0` to avoid randomness.\n",
        "- kNN regression - Values of `n_neighbors` of 1, 5, 10, and 15. Use the [KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html) class.\n",
        "\n",
        "Additional notes:\n",
        "1. All models should use the feature sets described in Part 1.3 (the same ...one-hot encoded... categorical variables, and the scaled continuous variables)\n",
        "2. As opposed to using the `KFold` class from `sklearn` like we did in class, we have instead provided you with pre-existing data sets; you should therefore use the pre-split data in the provided CSV files ``1.2_fold0.csv ... 1.2_fold4.csv``\n",
        "\n",
        "**What to submit**:\n",
        "\n",
        "1. Write out the result to a file called `part_1.4_results.csv` and submit this along with your assignment. The file should have the following columns:\n",
        "- `model_name` - The name of the model, one of `DTR` (Decision Tree Regression), `Ridge`, or `KNN`.\n",
        "- `hyperparameter_setting` - a column describing the hyperparameters of the model. For models with multiple hyperparameters, combine them using an underscore (you can do this with the code `\"_\".join(hyperparameters)`).\n",
        "- `mean_training_rmse` - a column that gives the mean RMSE on the k-fold training data. You should take the average of the model’s errors on the different folds, using root mean squared error again as your evaluation metric.\n",
        "- `sd_training_rmse` - a column that gives the standard deviation RMSE on the k-fold training data.\n",
        "- `test_rmse` - a column that gives the RMSE of a linear regression model trained on this feature set on the test data\n",
        "\n",
        "\n",
        "2. Answer the following questions:\n",
        "- **1.4.1** Report, for each model, the hyper parameter setting that resulted in the best performance\n",
        "- **1.4.2** Which model performed the best overall on the cross-validation? \n",
        "- **1.4.3** Which model performed the best overall on the final test set? \n",
        "- **1.4.4** With respect to your answer for 1.4.3, why do you think that might be? (*Note: there is more than one correct way to answer this question*)\n",
        "- **1.4.5** Which model/hyperparameter setting had the highest standard deviation across the different folds of the cross validation?\n",
        "- **1.4.6** With respect to your answer for 1.4.6, why do you think that might be? (*Note: there is more than one correct way to answer this question*)"
      ],
      "id": "appropriate-lesbian"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2mQ1OHG0RFg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "from sklearn.pipeline import Pipeline,make_pipeline\n",
        "from  sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "folds = []\n",
        "for i in range(5):\n",
        "    folds.append(pd.read_csv('1.2_fold{}.csv'.format(i)))\n",
        "\n",
        "CONTINUOUS_FEATURES = ['releaseyear', 'danceability', 'energy', 'key', 'loudness',\n",
        "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
        "       'valence', 'tempo']\n",
        "CATEGORICAL_FEATURES = ['artist', 'reviewauthor', 'recordlabel', 'genre']"
      ],
      "id": "-2mQ1OHG0RFg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDyytCZX0hYz"
      },
      "outputs": [],
      "source": [
        "basic_pipeline = make_pipeline(\n",
        "        ColumnTransformer([('numerical', StandardScaler(), CONTINUOUS_FEATURES),\n",
        "                           (\"categorical\", OneHotEncoder(categories='auto', drop='if_binary', sparse=False,handle_unknown = 'ignore'),CATEGORICAL_FEATURES)]),\n",
        "    )\n",
        "\n",
        "reg2 = Ridge(random_state=0)\n",
        "reg3 = KNeighborsRegressor()\n",
        "reg1 = DecisionTreeRegressor(random_state=0)\n",
        "\n",
        "\n",
        "\n",
        "# Building the pipelines\n",
        "pipe1 = Pipeline([(\"pipe\",basic_pipeline),\n",
        "                  ('reg1', reg1)])\n",
        "\n",
        "pipe2 = Pipeline([(\"pipe\",basic_pipeline),\n",
        "                  ('reg2', reg2)])\n",
        "\n",
        "pipe3 = Pipeline([(\"pipe\",basic_pipeline),\n",
        "                  ('reg3', reg3)])\n",
        "\n",
        "\n",
        "# Setting up the parameter grids\n",
        "param_grid1 = [{'reg1__max_depth' : [5,10,15],\n",
        "                'reg1__criterion' : ['squared_error','absolute_error' ]}]\n",
        "param_grid2 = [{'reg2__alpha' : np.logspace(-5,5,11).tolist()}]\n",
        "param_grid3 = [{'reg3__n_neighbors': [ 1,5,10,15]}]\n",
        "\n"
      ],
      "id": "rDyytCZX0hYz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEnuFMyN0veO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "gridcvs = {}\n",
        "inner_cv = KFold(n_splits=5, shuffle=False)\n",
        "\n",
        "for pgrid, est, name in zip((param_grid1, param_grid2, param_grid3),\n",
        "                            (pipe1, pipe2,pipe3),\n",
        "                            ('DTR', 'Ridge','KNN')):\n",
        "    gcv = GridSearchCV(estimator=est,\n",
        "                       param_grid=pgrid,\n",
        "                       scoring='neg_mean_squared_error',\n",
        "                       cv=inner_cv,\n",
        "                       verbose=3,\n",
        "                       refit=True)\n",
        "    gridcvs[name] = gcv"
      ],
      "id": "uEnuFMyN0veO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t_VYmn5J0x1e",
        "outputId": "c849e3d1-54c3-43e5-dcea-87c4dab5214e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------- \n",
            "\n",
            "Algorithm: DTR\n",
            "    Inner loop:\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END reg1__criterion=squared_error, reg1__max_depth=5;, score=-1.446 total time=   0.6s\n",
            "[CV 2/5] END reg1__criterion=squared_error, reg1__max_depth=5;, score=-1.377 total time=   0.7s\n",
            "[CV 3/5] END reg1__criterion=squared_error, reg1__max_depth=5;, score=-1.557 total time=   0.6s\n",
            "[CV 4/5] END reg1__criterion=squared_error, reg1__max_depth=5;, score=-1.489 total time=   0.6s\n",
            "[CV 5/5] END reg1__criterion=squared_error, reg1__max_depth=5;, score=-1.426 total time=   0.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END reg1__criterion=squared_error, reg1__max_depth=10;, score=-1.543 total time=   0.9s\n",
            "[CV 2/5] END reg1__criterion=squared_error, reg1__max_depth=10;, score=-1.488 total time=   0.9s\n",
            "[CV 3/5] END reg1__criterion=squared_error, reg1__max_depth=10;, score=-1.648 total time=   1.0s\n",
            "[CV 4/5] END reg1__criterion=squared_error, reg1__max_depth=10;, score=-1.609 total time=   0.9s\n",
            "[CV 5/5] END reg1__criterion=squared_error, reg1__max_depth=10;, score=-1.495 total time=   1.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END reg1__criterion=squared_error, reg1__max_depth=15;, score=-1.712 total time=   1.2s\n",
            "[CV 2/5] END reg1__criterion=squared_error, reg1__max_depth=15;, score=-1.607 total time=   1.1s\n",
            "[CV 3/5] END reg1__criterion=squared_error, reg1__max_depth=15;, score=-1.752 total time=   1.3s\n",
            "[CV 4/5] END reg1__criterion=squared_error, reg1__max_depth=15;, score=-1.725 total time=   1.1s\n",
            "[CV 5/5] END reg1__criterion=squared_error, reg1__max_depth=15;, score=-1.688 total time=   1.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END reg1__criterion=absolute_error, reg1__max_depth=5;, score=-1.460 total time= 2.5min\n",
            "[CV 2/5] END reg1__criterion=absolute_error, reg1__max_depth=5;, score=-1.458 total time= 2.4min\n",
            "[CV 3/5] END reg1__criterion=absolute_error, reg1__max_depth=5;, score=-1.587 total time= 2.6min\n",
            "[CV 4/5] END reg1__criterion=absolute_error, reg1__max_depth=5;, score=-1.544 total time= 2.6min\n",
            "[CV 5/5] END reg1__criterion=absolute_error, reg1__max_depth=5;, score=-1.471 total time= 2.7min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END reg1__criterion=absolute_error, reg1__max_depth=10;, score=-1.492 total time= 3.1min\n",
            "[CV 2/5] END reg1__criterion=absolute_error, reg1__max_depth=10;, score=-1.506 total time= 3.0min\n",
            "[CV 3/5] END reg1__criterion=absolute_error, reg1__max_depth=10;, score=-1.606 total time= 3.3min\n",
            "[CV 4/5] END reg1__criterion=absolute_error, reg1__max_depth=10;, score=-1.613 total time= 3.2min\n",
            "[CV 5/5] END reg1__criterion=absolute_error, reg1__max_depth=10;, score=-1.576 total time= 3.6min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END reg1__criterion=absolute_error, reg1__max_depth=15;, score=-1.586 total time= 3.6min\n",
            "[CV 2/5] END reg1__criterion=absolute_error, reg1__max_depth=15;, score=-1.622 total time= 3.4min\n",
            "[CV 3/5] END reg1__criterion=absolute_error, reg1__max_depth=15;, score=-1.786 total time= 3.6min\n",
            "[CV 4/5] END reg1__criterion=absolute_error, reg1__max_depth=15;, score=-1.780 total time= 3.6min\n",
            "[CV 5/5] END reg1__criterion=absolute_error, reg1__max_depth=15;, score=-1.683 total time= 3.9min\n",
            "\n",
            "        Best MSE (avg. of inner test folds) 1.458993453714207\n",
            "        Best parameters: {'reg1__criterion': 'squared_error', 'reg1__max_depth': 5}\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-8ce4fc39d2f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mhyperparameter_setting\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtest_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridcvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     cv_results.append({'model_name':name,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0mscore_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;31m# ndarray was used for fitting or transforming, thus we only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0;31m# check that n_features_in_ is consistent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         Xs = self._fit_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: X has 691 features, but ColumnTransformer is expecting 15 features as input."
          ]
        }
      ],
      "source": [
        "# train_data = pd.concat(folds)\n",
        "\n",
        "# train_X = train_data.drop(columns = ['score'])\n",
        "# train_y = train_data['score']\n",
        "\n",
        "# test_X = test_data.drop.drop(columns = ['score'])\n",
        "# test_y = test_data['score']\n",
        "\n",
        "# cv_results = []\n",
        "\n",
        "# for name, gs_est in sorted(gridcvs.items()):\n",
        "#     print(50 * '-', '\\n')\n",
        "#     print('Algorithm:', name)\n",
        "#     print('    Inner loop:')\n",
        "    \n",
        "#     outer_scores = []\n",
        "\n",
        "#     gridcvs[name].fit(train_X, \n",
        "#                       train_y) # run inner loop hyperparam tuning\n",
        "#     print('\\n        Best MSE (avg. of inner test folds) {}'.format(gridcvs[name].best_score_ *-1))\n",
        "#     print('        Best parameters:', gridcvs[name].best_params_)\n",
        "    \n",
        "#     res = pd.DataFrame(gridcvs[name].cv_results_)\n",
        "#     params = res.sort_values('mean_test_score').params.iloc[-1]\n",
        "\n",
        "#     hyperparameter_setting = '_'\n",
        "#     for i,j in zip(list(params.keys()), list(params.values())):\n",
        "#         hyperparameter_setting += str(i)[6:] + '_' +str(j) + '_'\n",
        "    \n",
        "#     test_rmse = gridcvs[name].best_estimator_.score(X_test, y_test)\n",
        "\n",
        "#     cv_results.append({'model_name':name,\n",
        "#                        'hyperparameter_setting':hyperparameter_setting,\n",
        "#                        'mean_training_rmse':abs(res.mean_test_score).min(),\n",
        "#                        'sd_training_rmse':res.sort_values('mean_test_score').std_test_score.iloc[-1],\n",
        "#                        'test_rmse':test_rmse})\n"
      ],
      "id": "t_VYmn5J0x1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8bE3a__ZY1o",
        "outputId": "5623a13a-8a35-4a38-a564-b837c05b8b62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------- \n",
            "\n",
            "Algorithm: KNN\n",
            "    Inner loop:\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END ..............reg3__n_neighbors=1;, score=-2.475 total time=   3.6s\n",
            "[CV 2/5] END ..............reg3__n_neighbors=1;, score=-2.504 total time=   3.1s\n",
            "[CV 3/5] END ..............reg3__n_neighbors=1;, score=-2.576 total time=   3.2s\n",
            "[CV 4/5] END ..............reg3__n_neighbors=1;, score=-2.579 total time=   2.8s\n",
            "[CV 5/5] END ..............reg3__n_neighbors=1;, score=-2.646 total time=   2.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END ..............reg3__n_neighbors=5;, score=-1.546 total time=   2.6s\n",
            "[CV 2/5] END ..............reg3__n_neighbors=5;, score=-1.524 total time=   2.5s\n",
            "[CV 3/5] END ..............reg3__n_neighbors=5;, score=-1.683 total time=   2.6s\n",
            "[CV 4/5] END ..............reg3__n_neighbors=5;, score=-1.591 total time=   2.6s\n",
            "[CV 5/5] END ..............reg3__n_neighbors=5;, score=-1.619 total time=   2.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END .............reg3__n_neighbors=10;, score=-1.429 total time=   2.6s\n",
            "[CV 2/5] END .............reg3__n_neighbors=10;, score=-1.431 total time=   2.5s\n",
            "[CV 3/5] END .............reg3__n_neighbors=10;, score=-1.562 total time=   2.6s\n",
            "[CV 4/5] END .............reg3__n_neighbors=10;, score=-1.517 total time=   2.7s\n",
            "[CV 5/5] END .............reg3__n_neighbors=10;, score=-1.485 total time=   2.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END .............reg3__n_neighbors=15;, score=-1.423 total time=   2.6s\n",
            "[CV 2/5] END .............reg3__n_neighbors=15;, score=-1.394 total time=   2.5s\n",
            "[CV 3/5] END .............reg3__n_neighbors=15;, score=-1.534 total time=   2.6s\n",
            "[CV 4/5] END .............reg3__n_neighbors=15;, score=-1.486 total time=   2.6s\n",
            "[CV 5/5] END .............reg3__n_neighbors=15;, score=-1.440 total time=   2.6s\n",
            "\n",
            "        Best MSE (avg. of inner test folds) 1.4555839623028068\n",
            "        Best parameters: {'reg3__n_neighbors': 15}\n",
            "-------------------------------------------------- \n",
            "\n",
            "Algorithm: Ridge\n",
            "    Inner loop:\n",
            "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END ................reg2__alpha=1e-05;, score=-1.323 total time=   0.4s\n",
            "[CV 2/5] END ................reg2__alpha=1e-05;, score=-1.316 total time=   0.5s\n",
            "[CV 3/5] END ................reg2__alpha=1e-05;, score=-1.470 total time=   0.4s\n",
            "[CV 4/5] END ................reg2__alpha=1e-05;, score=-1.396 total time=   0.5s\n",
            "[CV 5/5] END ................reg2__alpha=1e-05;, score=-1.359 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END ...............reg2__alpha=0.0001;, score=-1.323 total time=   0.5s\n",
            "[CV 2/5] END ...............reg2__alpha=0.0001;, score=-1.316 total time=   0.5s\n",
            "[CV 3/5] END ...............reg2__alpha=0.0001;, score=-1.470 total time=   0.5s\n",
            "[CV 4/5] END ...............reg2__alpha=0.0001;, score=-1.396 total time=   0.5s\n",
            "[CV 5/5] END ...............reg2__alpha=0.0001;, score=-1.359 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END ................reg2__alpha=0.001;, score=-1.323 total time=   0.5s\n",
            "[CV 2/5] END ................reg2__alpha=0.001;, score=-1.316 total time=   0.5s\n",
            "[CV 3/5] END ................reg2__alpha=0.001;, score=-1.470 total time=   0.5s\n",
            "[CV 4/5] END ................reg2__alpha=0.001;, score=-1.396 total time=   0.4s\n",
            "[CV 5/5] END ................reg2__alpha=0.001;, score=-1.359 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END .................reg2__alpha=0.01;, score=-1.323 total time=   0.5s\n",
            "[CV 2/5] END .................reg2__alpha=0.01;, score=-1.316 total time=   0.5s\n",
            "[CV 3/5] END .................reg2__alpha=0.01;, score=-1.470 total time=   0.4s\n",
            "[CV 4/5] END .................reg2__alpha=0.01;, score=-1.396 total time=   0.5s\n",
            "[CV 5/5] END .................reg2__alpha=0.01;, score=-1.359 total time=   0.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END ..................reg2__alpha=0.1;, score=-1.321 total time=   0.4s\n",
            "[CV 2/5] END ..................reg2__alpha=0.1;, score=-1.315 total time=   0.4s\n",
            "[CV 3/5] END ..................reg2__alpha=0.1;, score=-1.469 total time=   0.4s\n",
            "[CV 4/5] END ..................reg2__alpha=0.1;, score=-1.395 total time=   0.4s\n",
            "[CV 5/5] END ..................reg2__alpha=0.1;, score=-1.358 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END ..................reg2__alpha=1.0;, score=-1.313 total time=   0.5s\n",
            "[CV 2/5] END ..................reg2__alpha=1.0;, score=-1.305 total time=   0.4s\n",
            "[CV 3/5] END ..................reg2__alpha=1.0;, score=-1.462 total time=   0.5s\n",
            "[CV 4/5] END ..................reg2__alpha=1.0;, score=-1.388 total time=   0.4s\n",
            "[CV 5/5] END ..................reg2__alpha=1.0;, score=-1.348 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END .................reg2__alpha=10.0;, score=-1.299 total time=   0.5s\n",
            "[CV 2/5] END .................reg2__alpha=10.0;, score=-1.277 total time=   0.5s\n",
            "[CV 3/5] END .................reg2__alpha=10.0;, score=-1.451 total time=   0.5s\n",
            "[CV 4/5] END .................reg2__alpha=10.0;, score=-1.377 total time=   0.5s\n",
            "[CV 5/5] END .................reg2__alpha=10.0;, score=-1.329 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END ................reg2__alpha=100.0;, score=-1.361 total time=   0.4s\n",
            "[CV 2/5] END ................reg2__alpha=100.0;, score=-1.301 total time=   0.5s\n",
            "[CV 3/5] END ................reg2__alpha=100.0;, score=-1.495 total time=   0.4s\n",
            "[CV 4/5] END ................reg2__alpha=100.0;, score=-1.425 total time=   0.5s\n",
            "[CV 5/5] END ................reg2__alpha=100.0;, score=-1.367 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END ...............reg2__alpha=1000.0;, score=-1.452 total time=   0.5s\n",
            "[CV 2/5] END ...............reg2__alpha=1000.0;, score=-1.368 total time=   0.5s\n",
            "[CV 3/5] END ...............reg2__alpha=1000.0;, score=-1.567 total time=   0.5s\n",
            "[CV 4/5] END ...............reg2__alpha=1000.0;, score=-1.501 total time=   0.5s\n",
            "[CV 5/5] END ...............reg2__alpha=1000.0;, score=-1.427 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END ..............reg2__alpha=10000.0;, score=-1.502 total time=   0.5s\n",
            "[CV 2/5] END ..............reg2__alpha=10000.0;, score=-1.409 total time=   0.5s\n",
            "[CV 3/5] END ..............reg2__alpha=10000.0;, score=-1.611 total time=   0.5s\n",
            "[CV 4/5] END ..............reg2__alpha=10000.0;, score=-1.542 total time=   0.4s\n",
            "[CV 5/5] END ..............reg2__alpha=10000.0;, score=-1.455 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_encoders.py:174: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
            "  UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END .............reg2__alpha=100000.0;, score=-1.537 total time=   0.5s\n",
            "[CV 2/5] END .............reg2__alpha=100000.0;, score=-1.439 total time=   0.5s\n",
            "[CV 3/5] END .............reg2__alpha=100000.0;, score=-1.645 total time=   0.4s\n",
            "[CV 4/5] END .............reg2__alpha=100000.0;, score=-1.568 total time=   0.5s\n",
            "[CV 5/5] END .............reg2__alpha=100000.0;, score=-1.475 total time=   0.4s\n",
            "\n",
            "        Best MSE (avg. of inner test folds) 1.3466667038443543\n",
            "        Best parameters: {'reg2__alpha': 10.0}\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.concat(folds)\n",
        "\n",
        "train_X = train_data.drop(columns = ['score'])\n",
        "train_y = train_data['score']\n",
        "\n",
        "test_X = test_data[feature_set]\n",
        "test_y = test_data['score']\n",
        "\n",
        "cv_results = []\n",
        "\n",
        "for name, gs_est in sorted(gridcvs.items()):\n",
        "    print(50 * '-', '\\n')\n",
        "    print('Algorithm:', name)\n",
        "    print('    Inner loop:')\n",
        "    \n",
        "    outer_scores = []\n",
        "\n",
        "    gridcvs[name].fit(train_X, \n",
        "                      train_y) # run inner loop hyperparam tuning\n",
        "    print('\\n        Best MSE (avg. of inner test folds) {}'.format(gridcvs[name].best_score_ *-1))\n",
        "    print('        Best parameters:', gridcvs[name].best_params_)\n",
        "    \n",
        "    res = pd.DataFrame(gridcvs[name].cv_results_)\n",
        "    params = res.sort_values('mean_test_score').params.iloc[-1]\n",
        "\n",
        "    hyperparameter_setting = '_'\n",
        "    for i,j in zip(list(params.keys()), list(params.values())):\n",
        "        hyperparameter_setting += str(i)[6:] + '_' +str(j) + '_'\n",
        "\n",
        "    preds = gridcvs[name].best_estimator_.predict(test_X)\n",
        "    rmse_test = np.sqrt(np.mean(np.square(preds - test_y)))\n",
        "\n",
        "    cv_results.append({'model_name':name,\n",
        "                        'hyperparameter_setting':hyperparameter_setting,\n",
        "                        'mean_training_rmse':abs(res.mean_test_score).min(),\n",
        "                        'sd_training_rmse':res.sort_values('mean_test_score').std_test_score.iloc[-1],\n",
        "                        'test_rmse':rmse_test})\n"
      ],
      "id": "_8bE3a__ZY1o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "WP8FRrP3GHtz",
        "outputId": "9d51abd9-895f-4624-c103-025c869ec3c2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-057d27fa-5e3b-4af8-ae4b-4c3741e34dcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>hyperparameter_setting</th>\n",
              "      <th>mean_training_rmse</th>\n",
              "      <th>sd_training_rmse</th>\n",
              "      <th>test_rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DTR</td>\n",
              "      <td>_criterion_squared_error_max_depth_5_</td>\n",
              "      <td>1.458993</td>\n",
              "      <td>0.060825</td>\n",
              "      <td>1.202108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNN</td>\n",
              "      <td>_n_neighbors_15_</td>\n",
              "      <td>1.455584</td>\n",
              "      <td>0.049361</td>\n",
              "      <td>1.212350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ridge</td>\n",
              "      <td>_alpha_10.0_</td>\n",
              "      <td>1.346667</td>\n",
              "      <td>0.062092</td>\n",
              "      <td>1.161786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-057d27fa-5e3b-4af8-ae4b-4c3741e34dcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-057d27fa-5e3b-4af8-ae4b-4c3741e34dcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-057d27fa-5e3b-4af8-ae4b-4c3741e34dcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  model_name                 hyperparameter_setting  mean_training_rmse  \\\n",
              "0        DTR  _criterion_squared_error_max_depth_5_            1.458993   \n",
              "1        KNN                       _n_neighbors_15_            1.455584   \n",
              "2      Ridge                           _alpha_10.0_            1.346667   \n",
              "\n",
              "   sd_training_rmse  test_rmse  \n",
              "0          0.060825   1.202108  \n",
              "1          0.049361   1.212350  \n",
              "2          0.062092   1.161786  "
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "part_14_results = pd.DataFrame(cv_results)\n",
        "part_14_results"
      ],
      "id": "WP8FRrP3GHtz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOK1-cB8ec_R"
      },
      "outputs": [],
      "source": [
        "part_14_results.to_csv('part_1.4_results.csv')"
      ],
      "id": "cOK1-cB8ec_R"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neither-viking"
      },
      "source": [
        "# Part 2\n",
        "\n",
        "In class, we have shifted from regression to classification. Here, we're going to get a little practice in optimizing one of the classification models we saw in class - logistic regression. As a reminder...\n",
        "\n",
        "The loss function of logistic regression (also known as the logistic-loss or log-loss) is given by:\n",
        "\\begin{equation}\n",
        "  J({\\bf w}) = \\frac{1}{n}\\sum_{i=1}^n \\log{(1 + \\exp{(-y_i{\\bf w}^\\top{\\bf x}_i}))}\n",
        "  \\label{eqn:logloss}\n",
        "\\end{equation}\n",
        "\n",
        "The gradient for this loss function, as derived in class, is:\n",
        "\\begin{equation}\n",
        "  \\nabla J({\\bf w}) = -\\frac{1}{n}\\sum_{i=1}^n \\frac{y_i}{1 + \\exp{(y_i{\\bf w}^\\top{\\bf x}_i)}}{\\bf x}_i\n",
        "  \\label{eqn:loglossgradient}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "The Hessian for the loss function is given by:\n",
        "\\begin{equation}\n",
        "  {\\bf H}({\\bf w}) = \\frac{1}{n} \\sum_{i=1}^n \\frac{\\exp{(y_i{\\bf w}^\\top{\\bf x}_i)}}{(1 + \\exp{(y_i{\\bf w}^\\top{\\bf x}_i)})^2}{\\bf x}_i{\\bf x}_i^\\top\n",
        "  \\label{eqn:loglosshessian}\n",
        "\\end{equation}\n",
        "\n",
        "## Part 2.1 - Logistic Regression with Gradient Descent\n",
        "\n",
        "In Part 2.1 we will implement logistic regression with gradient descent. You need to finish implementing 3 functions:\n",
        "\n",
        "1. `logistic_objective` - compute the logistic loss for the given data set (see equation above)\n",
        "2. `logistic_gradient` - compute the gradient vector of logistic loss for the given data set (see equation above)\n",
        "3. `run_gradient_descent` - run the gradient descent algorithm, given these two functions.\n",
        "\n",
        "We have provided you with some simulation data to evaluate your method with. Part 2.1 will, however, largely be graded by evaluating your code on a slightly different dataset to ensure robustness. \n",
        "\n",
        "In addition, please submit answers to the following questions on your written report:\n",
        "\n",
        "- **2.1.1** - How did you go about selecting a good step size, i.e. one that was not too big or too small? (*Note: There is more than one correct answer to this*)\n",
        "- **2.1.2** - What is the condition under which we assume that the gradient descent algorithm has converged in the code here?\n",
        "- **2.1.3** - What is a different convergence metric we could have used? (*Note: There is more than one correct answer to this*)"
      ],
      "id": "neither-viking"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "standard-roulette"
      },
      "outputs": [],
      "source": [
        "\n",
        "import math as m\n",
        "def logistic_objective(w, X, y):\n",
        "\n",
        "    # compute log-loss error (scalar) with respect\n",
        "    # to w (vector) for the given data X and y                               \n",
        "    # Inputs:\n",
        "    # w = d x 1\n",
        "    # X = N x d\n",
        "    # y = N x 1\n",
        "    # Output:\n",
        "    # error = scalar\n",
        "    \n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    J = 0\n",
        "    N = len(y)\n",
        "    for i in range(N):\n",
        "      J += np.log(1+m.exp(-y[i]*np.dot(np.transpose(w),X[i])))\n",
        "    J = J/N\n",
        "    return J\n",
        "\n",
        "def logistic_gradient(w, X, y):\n",
        "\n",
        "    # compute the gradient of the log-loss error (vector) with respect\n",
        "    # to w (vector) for the given data X and y  \n",
        "    #\n",
        "    # Inputs:\n",
        "    # w = d x 1\n",
        "    # X = N x d\n",
        "    # y = N x 1\n",
        "    # Output:\n",
        "    # error = d length gradient vector (not a d x 1 matrix)\n",
        "\n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    grad = 0\n",
        "    N = len(y)\n",
        "    for i in range(len(X)):\n",
        "      grad += y[i]/(1+ np.exp(y[i]*np.dot(w,X[i])))*X[i]\n",
        "\n",
        "      #temp_dot = np.dot(np.transpose(w),X[i])\n",
        "      #print(y[i]*temp_dot)\n",
        "      #exp = math.exp(y[i]*temp_dot)\n",
        "      #temp = y[i]/exp\n",
        "      #gradient += temp*X[i]\n",
        "    gradient = -1*(grad/len(X))\n",
        "    return gradient\n",
        "\n",
        "def run_gradient_descent(X,y):\n",
        "    old_w = np.array([-1]*X.shape[1])\n",
        "    # change this value! This is an unreasonable step size\n",
        "    step_size = 0.05\n",
        "    new_w =old_w - 1\n",
        "    \n",
        "    while ((new_w-old_w)**2).sum() > .000001:\n",
        "        #IMPLEMENT THIS!\n",
        "        temp = new_w\n",
        "        new_w = old_w - step_size*logistic_gradient(old_w, X, y)\n",
        "        old_w = temp\n",
        "        print(new_w, old_w)\n",
        "        print(((new_w-old_w)**2).sum())\n",
        "\n",
        "    return new_w\n",
        "\n"
      ],
      "id": "standard-roulette"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crude-foundation"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import uniform, bernoulli\n",
        "import functools\n",
        "draw_binary = functools.partial(np.random.binomial,n=1)\n",
        "\n",
        "## Simulated data to test your method\n",
        "DATA_SIZE = 10000\n",
        "x1 = bernoulli(.5).rvs(DATA_SIZE)\n",
        "x2 = np.floor(uniform(18,60).rvs(DATA_SIZE))\n",
        "true_w = [-9, 3.5, 0.2]\n",
        "xb = true_w[0] + true_w[1]*x1 + true_w[2]*x2\n",
        "p = 1/(1 + np.exp(-xb))\n",
        "y = np.array([1 if draw_binary(p=v) else -1 for v in p])"
      ],
      "id": "crude-foundation"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noted-newton",
        "outputId": "f43460b2-d3bd-4cfa-c444-bc45d2e30229"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-8.32931976,  3.28459294,  0.18536353]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# notice that logistic regression as implemented in sklearn does not get the exact results either!\n",
        "# so you shouldn't worry if you're a bit off\n",
        "X = np.hstack([np.ones((len(xb),1)), x1[:,np.newaxis], x2[:,np.newaxis]])\n",
        "model = LogisticRegression(solver='liblinear', random_state=0,fit_intercept=False)\n",
        "model.fit(X,y).coef_"
      ],
      "id": "noted-newton"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "american-locking"
      },
      "outputs": [],
      "source": [
        "# this is how we will test your results\n",
        "gd_result = run_gradient_descent(X,y)\n",
        "# is your result relatively close to the truth?\n",
        "np.abs(true_w-gd_result).sum()"
      ],
      "id": "american-locking"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diagnostic-toddler"
      },
      "source": [
        "## <span style=\"color:red\"> 574 Only</span> Part 2.2 - Optimization with Newton-Raphson <span style=\"color:red\"> 574 Only</span>\n",
        "\n",
        "In Part 2.2, you are going to, instead of using gradient descent, use the Newton-Raphson method to optimize the same logistic regression model. To do so, you will need to 1) implement the `logistic_hessian` function to compute the Hessian matrix of logistic loss for the given data set, and 2) use `scipy`'s `optimize` function to perform the optimization, rather than writing a function by hand to do so.  \n",
        "\n",
        "For Part 2.2, you will only need to implement these functions, we will test them using our own code. You can, however, perform the same kinds of tests that we proposed above to check your work! "
      ],
      "id": "diagnostic-toddler"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "conscious-spokesman"
      },
      "outputs": [],
      "source": [
        "def logistic_hessian(w, X, y):\n",
        "\n",
        "    # compute the Hessian of the log-loss error (matrix) with respect\n",
        "    # to w (vector) for the given data X and y                               \n",
        "    #\n",
        "    # Inputs:\n",
        "    # w = d x 1\n",
        "    # X = N x d\n",
        "    # y = N x 1\n",
        "    # Output:\n",
        "    # Hessian = d x d matrix\n",
        "    \n",
        "    \n",
        "    if len(w.shape) == 1:\n",
        "        w = w[:,np.newaxis]\n",
        "\n",
        "    # IMPLEMENT THIS METHOD - REMOVE THE NEXT LINE\n",
        "    loss = 0\n",
        "    for i in range(len(X)):\n",
        "      x= np.array(X[i])\n",
        "      num = m.exp(y[i]*(np.dot(np.transpose(w),x)))\n",
        "      den = (1+num)**2\n",
        "      x = x.reshape(3,1)\n",
        "      loss += (num/den)*x*np.transpose(x)\n",
        "    \n",
        "    hessian = loss/len(X)\n",
        "    return hessian"
      ],
      "id": "conscious-spokesman"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bored-determination"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "def run_newton_raphson(X,y):\n",
        "    args = (X,y[:,np.newaxis])\n",
        "    opts = {'maxiter' : 50}    # Preferred value.    \n",
        "    w_init = np.zeros(X.shape[1])\n",
        "    \n",
        "    # note: this is *almost* what you need, you just need to figure out what arguments are necessary here!\n",
        "    soln = minimize(logistic_objective,\n",
        "                    x0 = w_init,\n",
        "                    args=args,\n",
        "                    jac = logistic_gradient,\n",
        "                    hess = logistic_hessian,\n",
        "                    method='Newton-CG',\n",
        "                    options=opts)\n",
        "\n",
        "    w = np.transpose(np.array(soln.x))\n",
        "    w = w[:,np.newaxis]\n",
        "    return w\n"
      ],
      "id": "bored-determination"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liable-station",
        "outputId": "cac1c4fd-7647-4aa2-bc57-bbd3f9a30624"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-8.69093471],\n",
              "       [ 3.43625596],\n",
              "       [ 0.19280142]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_newton_raphson(X,y)"
      ],
      "id": "liable-station"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c7qQKRR9w0-"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "9c7qQKRR9w0-"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment2-Student.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}